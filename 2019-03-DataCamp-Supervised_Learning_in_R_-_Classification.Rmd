---
title: "Aprendizagem Supervisionada de Classificação em R"
author: "Pedro Almeida"
date: "11 de março de 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1) k-Nearest Neighbors (kNN)

O kNN mede a similaridade pela distância Euclidiana, que é dada pela seguinte fórmula:

$$ dist(p,q) = \sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 +...+(p_n - q_n)^2} $$

O kNN literalmente aprende pelo exemplo, e é um bom método para começar a entender o aprendizado de máquina supervisionado de classificação. Nessa primeira parte do código apresentarei a aplicação do kNN no reconhecimento de sinais de trânsito de veículos autônomos.

### 1.1) Reconhecimento de sinais de trânsito com kNN

Usarei o dataset signs e o next_sign, o next_sign possui as observaçoes que irei classificar.

```{r, message=FALSE, warning=FALSE}

# carregando o pacote class
library(class)

# carregando os datasets
signs <- read.csv(file = "signs.csv", sep = ";")
next_sign <- read.csv(file = "next_sign.csv", sep = ";")

# criando o vetor dos rótulos
sign_types <- signs$sign_type

# classificando o próximo sinal observado
knn(train = signs[-1], test = next_sign, cl = sign_types)

```

Explorando o dataset signs.

```{r, message=FALSE, warning=FALSE}

# estrutura do signs
str(signs)

# contanto o número de sinais de cada tipo
table(signs$sign_type)

# checando a média da feature r10 (vermelho) por tipo de sinal
aggregate(r10 ~ sign_type, data = signs, mean)

```

Era esperado que os sinais de parada tivessem um valor médio de vermelho mais alto. É assim que o kNN identifica sinais semelhantes nesse exemplo.

Agora vou fazer previsões com dados não vistos e avaliar a performance do kNN. 

```{r, message=FALSE, warning=FALSE}

# carregando o dataset de teste
signs_test <- read.csv(file = "signs_test.csv", sep = ";")

# usando o kNN para identificar os sinais no dataset de teste
signs_pred <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types)

# matriz de confusão das previsões X os valores atuais
signs_actual <- signs_test$sign_type
table(signs_pred, signs_actual)

# Compute the accuracy
mean(signs_pred == signs_actual)

```

A matriz de confusão permite verificar os erros do modelo classificador, no caso desse exemplo, o kNN.

### 1.2) Testando outros valores de k

A função knn() do pacote class usa apenas o vizinho mais próximo.

Definir o parâmetro k permite que o algoritmo considere vizinhos mais próximos adicionais. Isso amplia a coleção de vizinhos que votarão na classe prevista.

Vou comparar os valores k de 1, 7 e 15 para examinar o impacto na precisão da classificação do sinal de trânsito.

```{r, message=FALSE, warning=FALSE}

# default, k = 1
k_1 <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types)
mean(signs_actual == k_1)

# k = 7
k_7 <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types, k = 7)
mean(signs_actual == k_7)

# k = 15
k_15 <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types, k = 15)
mean(signs_actual == k_15)

```

O modelo configurado com o k igual a 7 possui a melhor acurácia!

### 1.3) Verificando como os vizinhos votam

Quando vários vizinhos mais próximos realizam um voto, pode ser útil examinar se os votantes foram unânimes ou se são amplamente separados.

Por exemplo, saber mais sobre os votantes na classificação pode permitir que um veículo autônomo seja mais cauteloso quando haver alguma chance de um sinal de parada estar próximo.

```{r, message=FALSE, warning=FALSE}

# usando o argumento prob para obter a proporção de votoss da classe vencedora
sign_pred <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types, k = 7, prob = TRUE)

# obtendo o atributo "prob" das classes preditas
sign_prob <- attr(sign_pred, "prob")

# verificando as cinco primeiras predições
head(sign_pred)

# verificando as proporções de votos da classe vencedora
head(sign_prob)

```

## 2) Naive Bayes

Naive Bayes usa princípios do campo da estatística para fazer previsões. Apresentarei os fundamentos do método bayesiano aplicado às sugestões de destinos, semelhantes ao iPhone.

### 2.1) Computando probabilidades

O dataset where9am contém 91 dias (treze semanas) com dos dados de localização de uma pessoa as 9h, e se o tipo de dia era  de um fim de semana ou dia da semana.

Usando a fórmula de probabilidade condicional abaixo, calcularei a probabilidade de que essa pessoa desses dados esteja trabalhando no escritório, dado que é um dia da semana.

$$ P(A|B) = \frac{P(A\ and\ B)}{P(B)} $$

```{r, message=FALSE, warning=FALSE}

#carregando o arquivo
where9am <- read.csv(file = "where9am.csv", sep = ";")

# computando a P(A) 
p_A <- nrow(subset(where9am, location == "office")) / nrow(where9am)

# computando a P(B)
p_B <- nrow(subset(where9am, daytype == "weekday")) / nrow(where9am)

# computando P(A and B)
p_AB <- nrow(subset(where9am, location == "office" & daytype == "weekday")) / nrow(where9am)

# computando P(A|B)
p_A_given_B <- p_AB / p_B
p_A_given_B

```