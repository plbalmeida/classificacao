---
title: "Aprendizagem Supervisionada de Classificação em R"
author: "Pedro Almeida"
date: "11 de março de 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1) k-Nearest Neighbors (kNN)

O kNN mede a similaridade pela distância Euclidiana, que é dada pela seguinte fórmula:

$$ dist(p,q) = \sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 +...+(p_n - q_n)^2} $$

O kNN literalmente aprende pelo exemplo, e é um bom método para começar a entender o aprendizado de máquina supervisionado de classificação. Nessa primeira parte do código apresentarei a aplicação do kNN no reconhecimento de sinais de trânsito de veículos autônomos.

### 1.1) Reconhecimento de sinais de trânsito com kNN

Usarei o dataset signs e o next_sign, o next_sign possui as observaçoes que irei classificar.

```{r, message=FALSE, warning=FALSE}

# carregando o pacote class
library(class)

# carregando os datasets
signs <- read.csv(file = "signs.csv", sep = ";")
next_sign <- read.csv(file = "next_sign.csv", sep = ";")

# criando o vetor dos rótulos
sign_types <- signs$sign_type

# classificando o próximo sinal observado
knn(train = signs[-1], test = next_sign, cl = sign_types)

```

Explorando o dataset signs.

```{r, message=FALSE, warning=FALSE}

# estrutura do signs
str(signs)

# contanto o número de sinais de cada tipo
table(signs$sign_type)

# checando a média da feature r10 (vermelho) por tipo de sinal
aggregate(r10 ~ sign_type, data = signs, mean)

```

Era esperado que os sinais de parada tivessem um valor médio de vermelho mais alto. É assim que o kNN identifica sinais semelhantes nesse exemplo.

Agora vou fazer previsões com dados não vistos e avaliar a performance do kNN. 

```{r, message=FALSE, warning=FALSE}

# carregando o dataset de teste
signs_test <- read.csv(file = "signs_test.csv", sep = ";")

# usando o kNN para identificar os sinais no dataset de teste
signs_pred <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types)

# matriz de confusão das previsões X os valores atuais
signs_actual <- signs_test$sign_type
table(signs_pred, signs_actual)

# Compute the accuracy
mean(signs_pred == signs_actual)

```

A matriz de confusão permite verificar os erros do modelo classificador, no caso desse exemplo, o kNN.

### 1.2) Testando outros valores de k

A função knn() do pacote class usa apenas o vizinho mais próximo.

Definir o parâmetro k permite que o algoritmo considere vizinhos mais próximos adicionais. Isso amplia a coleção de vizinhos que votarão na classe prevista.

Vou comparar os valores k de 1, 7 e 15 para examinar o impacto na precisão da classificação do sinal de trânsito.

```{r, message=FALSE, warning=FALSE}

# default, k = 1
k_1 <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types)
mean(signs_actual == k_1)

# k = 7
k_7 <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types, k = 7)
mean(signs_actual == k_7)

# k = 15
k_15 <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types, k = 15)
mean(signs_actual == k_15)

```

O modelo configurado com o k igual a 7 possui a melhor acurácia!

### 1.3) Verificando como os vizinhos votam

Quando vários vizinhos mais próximos realizam um voto, pode ser útil examinar se os votantes foram unânimes ou se são amplamente separados.

Por exemplo, saber mais sobre os votantes na classificação pode permitir que um veículo autônomo seja mais cauteloso quando haver alguma chance de um sinal de parada estar próximo.

```{r, message=FALSE, warning=FALSE}

# usando o argumento prob para obter a proporção de votoss da classe vencedora
sign_pred <- knn(train = signs[-1], test = signs_test[-1], cl = sign_types, k = 7, prob = TRUE)

# obtendo o atributo "prob" das classes preditas
sign_prob <- attr(sign_pred, "prob")

# verificando as cinco primeiras predições
head(sign_pred)

# verificando as proporções de votos da classe vencedora
head(sign_prob)

```

## 2) Naive Bayes

Naive Bayes usa princípios do campo da estatística para fazer previsões. Apresentarei os fundamentos do método bayesiano aplicado às sugestões de destinos, semelhantes ao iPhone.

### 2.1) Computando probabilidades

O dataset where9am contém 91 dias (treze semanas) com dos dados de localização de uma pessoa as 9h, e se o tipo de dia era  de um fim de semana ou dia da semana.

Usando a fórmula de probabilidade condicional abaixo, calcularei a probabilidade de que essa pessoa desses dados esteja trabalhando no escritório, dado que é um dia da semana.

$$ P(A|B) = \frac{P(A\ and\ B)}{P(B)} $$

```{r, message=FALSE, warning=FALSE}

#carregando o arquivo
where9am <- read.csv(file = "where9am.csv", sep = ";")

# computando a P(A) 
p_A <- nrow(subset(where9am, location == "office")) / nrow(where9am)

# computando a P(B)
p_B <- nrow(subset(where9am, daytype == "weekday")) / nrow(where9am)

# computando P(A and B)
p_AB <- nrow(subset(where9am, location == "office" & daytype == "weekday")) / nrow(where9am)

# computando P(A|B)
p_A_given_B <- p_AB / p_B
p_A_given_B

```

### 2.2) Modelo simples de localização com Naive Bayes 

Mostrei que a probabilidade dessa pessoa estar no trabalho ou em casa às 9h é altamente dependente se é fim de semana ou um dia da semana.

Para ver essa descoberta em ação, usarei os dados do where9am para criar um modelo Naive Bayes.

Assim podemos usar esse modelo para prever o futuro: onde o modelo vai dizer que essa pessoa estará às 9h da quinta-feira e às 9h do sábado?

```{r, message=FALSE, warning=FALSE}

# carregando o pacote naivebayes
library(naivebayes)

# modelo de previsão de localização
locmodel <- naive_bayes(location ~ daytype, data = where9am)

# previsão da localização as 9h na quinta-feira
thursday9am <- data.frame(daytype = factor(x = c("weekday"), levels = c("weekday", "weekend")))
predict(locmodel, thursday9am)

# previsão da localização as 9h na quinta-feira
saturday9am <- data.frame(daytype = factor(x = c("weekend"), levels = c("weekday", "weekend")))
predict(locmodel, saturday9am)

```

É mais provável essa pessoa estar no escritório às 9h numa quinta-feira, porém em casa no mesmo horário em um sábado!

### 2.3) Examinando probabilidades

O pacote naivebayes oferece várias maneiras de espiar o um modelo Naive Bayes por dentro.

Digitar o nome do objeto do modelo fornece as probabilidades a priori e condicional de cada um dos preditores do modelo. Podemos usar essas probabilidades para calcular as probabilidades posteriores (previstas) na mão, porém o R calcula as probabilidades posteriores se o argumento *type = "prob"* estiver configurado na função predict().

Usando esse método, examinarei como a probabilidade de localização prevista do modelo varia de acordo com o dia-a-dia.

```{r, message=FALSE, warning=FALSE}

# verificando o modelo de previsão de localização
locmodel

# obtendo as probabilidades previstas para quinta-feira as 9h
predict(locmodel, thursday9am, type = "prob")

# obtendo as probabilidades previstas para sábado as 9h
predict(locmodel, saturday9am, type = "prob")

```

Ótimo! Notou que a probabilidade dessa pessoa estar no escritório em um sábado e as 9h é zero?

## 3) Regressão Logística

A regressão logística envolve ajustar uma curva aos dados numéricos para fazer previsões sobre eventos binários. Indiscutivelmente esse é um dos métodos de aprendizado de máquina mais amplamente utilizados, darei uma visão geral da técnica enquanto ilustro como aplicá-lo aos dados de captação de recursos.

### 3.1) Contruindo um modelo de regressão linear simples

O conjunto de dados donors contém 93.462 registros de pessoas que receberam por correio uma solicitação de angariação de fundos para veteranos militares deficientes físicos. A coluna donated é 1 se a pessoa fez uma doação em resposta à correspondência, e 0 no caso contrário. Este resultado binário será a variável dependente para o modelo de regressão logística.

As colunas restantes são características dos possíveis doadores que podem influenciar no seu comportamento de doação. Estas são as variáveis independentes do modelo.

Ao construir um modelo de regressão, geralmente é útil formar uma hipótese sobre quais variáveis independentes serão preditivas da variável dependente. A coluna bad_address, que é definida como 1 para um endereço de correspondência inválido e 0 caso contrário, parece reduzir as chances de uma doação. Da mesma forma, pode-se suspeitar que o interesse religioso (interest_religion) e o interesse em assuntos de veteranos (interest_veterans) estariam associados a doação.

Usarei esses três fatores para criar um modelo simples de comportamento de doação.

```{r, message=FALSE, warning=FALSE}

# carregando o dataset donors
donors <- read.csv(file = "donors.csv", sep = ",")

# examiando o dataset e identificando as potenciais variáveis independentes para o modelo
str(donors)

# explorando a variável dependente
table(donors$donated)

# modelo
donation_model <- glm(donated ~ bad_address + interest_religion + interest_veterans, data = donors, family = "binomial")

# verificando o modelo
summary(donation_model)

```

### 3.2) Fazendo previsões binárias

Muitos dos métodos de aprendizado de máquina em R utilizam a função predict() no objeto do modelo para prever o comportamento futuro. Como padrão o predict() gera previsões em log odds, a menos que o argumento *type = "response"* seja especificade, isso converte de log para  probabilidade.

Como o modelo de regressão logística estima a probabilidade do resultado, cabe a você determinar esse limite (treshold). Por exemplo, se você definir que o treshhold é de 99% ou mais de probabilidade de doação, você perderia muitas pessoas com probabilidades estimadas mais baixas que ainda optam por doar. Este equilíbrio é particularmente importante ser considerado para resultados extremamente desequilibrados, no dataset donors as doações são relativamente raras.

```{r, message=FALSE, warning=FALSE}

# estimadno a probabilidade de doação
donors$donation_prob <- predict(donation_model, type = "response")

# média de doações
mean(donors$donated)

# prevendo se doa pela média da probabilidade de doação
donors$donation_pred <- ifelse(donors$donation_prob > 0.0504, 1, 0)

# calculando a acurácia do modelo
mean(donors$donated == donors$donation_pred)

```

Com uma acurácia de quase 80%, o modelo parece estar fazendo um bom trabalho. Mas não é bom demais para ser verdade?

Obs.: código em contrução, continua...

